#############out
tensor([[-1.9719e-01,  2.3412e-01, -2.3375e-01, -3.5949e-01,  3.1493e-01,
          2.1280e-02, -1.6230e-01,  2.2609e-01,  9.9259e-02, -8.9487e-03,
         -1.2326e-01, -6.6921e-02, -2.1031e-01,  1.4582e-01,  4.4872e-02,
         -2.4799e-01,  2.0754e-01, -1.4168e-02,  8.0886e-02, -5.1532e-02,
         -2.3612e-01, -9.2696e-02,  1.9784e-01,  2.1003e-01, -3.4126e-02,
          2.5569e-01,  1.8658e-02, -1.3506e-01, -1.2865e-01, -2.2796e-01,
          1.3366e-01,  1.4914e-01],
        [-3.7047e-01,  2.2606e-01, -1.7789e-01, -2.4328e-01,  2.7211e-01,
          2.4463e-02, -1.4279e-01,  1.2670e-01,  1.1929e-01, -1.8990e-02,
         -1.4294e-01,  8.3387e-03, -3.1684e-01, -3.8834e-02, -6.0730e-02,
         -3.5171e-01,  1.0670e-01, -8.2280e-02,  7.3433e-02, -2.7017e-02,
         -2.5675e-01, -6.2788e-02,  1.8553e-01,  1.8322e-01,  4.0124e-02,
          1.6148e-01, -5.2636e-03, -1.8818e-01, -1.8787e-01, -1.7226e-01,
          1.7757e-01,  1.4328e-01],
        [-4.6725e-01,  1.8733e-01, -1.0486e-01, -1.0920e-01,  1.9703e-01,
          2.3756e-02, -1.0593e-01,  2.3468e-02,  1.1971e-01, -2.4946e-02,
         -1.3975e-01,  7.1837e-02, -3.6380e-01, -1.9205e-01, -1.4293e-01,
         -3.9135e-01,  5.0378e-03, -1.2923e-01,  5.6697e-02, -2.1496e-03,
         -2.3836e-01, -2.8255e-02,  1.4885e-01,  1.3440e-01,  9.8283e-02,
          5.7804e-02, -2.5079e-02, -2.0736e-01, -2.1233e-01, -1.0016e-01,
          1.9032e-01,  1.1807e-01],
        [-5.0367e-01,  1.2440e-01, -1.8287e-02,  3.8988e-02,  9.6496e-02,
          1.9980e-02, -5.5394e-02, -8.2794e-02,  1.0468e-01, -2.7681e-02,
         -1.1850e-01,  1.2606e-01, -3.6377e-01, -3.2045e-01, -2.0667e-01,
         -3.8044e-01, -9.7278e-02, -1.5949e-01,  3.2638e-02,  2.2995e-02,
         -1.8918e-01,  9.9276e-03,  9.2950e-02,  6.8227e-02,  1.4375e-01,
         -5.3336e-02, -4.1655e-02, -1.9975e-01, -2.0936e-01, -1.5121e-02,
          1.7849e-01,  7.7622e-02],
        [-4.6360e-01,  3.0798e-02,  8.5452e-02,  2.0506e-01, -3.6293e-02,
          1.2315e-02,  1.2489e-02, -1.9290e-01,  7.0040e-02, -2.6331e-02,
         -7.4368e-02,  1.6851e-01, -3.0418e-01, -4.1742e-01, -2.4701e-01,
         -3.0546e-01, -2.0042e-01, -1.6860e-01, -7.0405e-04,  4.8492e-02,
         -1.0097e-01,  5.2736e-02,  1.2674e-02, -1.9953e-02,  1.7312e-01,
         -1.7394e-01, -5.4125e-02, -1.5819e-01, -1.7163e-01,  8.6316e-02,
          1.3549e-01,  1.7838e-02],
        [ 1.1017e-02,  2.0072e-01, -2.4820e-01, -4.1202e-01,  3.0197e-01,
          1.4329e-02, -1.5307e-01,  2.8543e-01,  6.1651e-02,  2.6773e-03,
         -8.1747e-02, -1.3033e-01, -6.6533e-02,  3.0465e-01,  1.4253e-01,
         -1.0035e-01,  2.7162e-01,  5.6454e-02,  7.4012e-02, -6.6920e-02,
         -1.7366e-01, -1.0618e-01,  1.7510e-01,  1.9964e-01, -1.0233e-01,
          3.0461e-01,  3.9274e-02, -5.8015e-02, -4.6642e-02, -2.4329e-01,
          6.6076e-02,  1.2860e-01],
        [-1.3043e-01,  1.5486e-01, -1.5461e-01, -2.3778e-01,  2.0831e-01,
          1.4076e-02, -1.0735e-01,  1.4954e-01,  6.5654e-02, -5.9190e-03,
         -8.1529e-02, -4.4264e-02, -1.3911e-01,  9.6452e-02,  2.9680e-02,
         -1.6403e-01,  1.3728e-01, -9.3710e-03,  5.3501e-02, -3.4085e-02,
         -1.5618e-01, -6.1312e-02,  1.3086e-01,  1.3892e-01, -2.2572e-02,
          1.6912e-01,  1.2341e-02, -8.9334e-02, -8.5095e-02, -1.5078e-01,
          8.8408e-02,  9.8650e-02],
        [-2.3362e-01,  9.3664e-02, -5.2430e-02, -5.4601e-02,  9.8513e-02,
          1.1878e-02, -5.2967e-02,  1.1734e-02,  5.9856e-02, -1.2473e-02,
         -6.9873e-02,  3.5919e-02, -1.8190e-01, -9.6023e-02, -7.1465e-02,
         -1.9568e-01,  2.5189e-03, -6.4617e-02,  2.8349e-02, -1.0748e-03,
         -1.1918e-01, -1.4128e-02,  7.4427e-02,  6.7201e-02,  4.9141e-02,
          2.8902e-02, -1.2539e-02, -1.0368e-01, -1.0617e-01, -5.0080e-02,
          9.5160e-02,  5.9037e-02],
        [-3.0664e-01,  2.0371e-02,  5.6521e-02,  1.3563e-01, -2.4005e-02,
          8.1458e-03,  8.2610e-03, -1.2759e-01,  4.6327e-02, -1.7416e-02,
         -4.9190e-02,  1.1146e-01, -2.0120e-01, -2.7609e-01, -1.6338e-01,
         -2.0204e-01, -1.3256e-01, -1.1152e-01, -4.6568e-04,  3.2074e-02,
         -6.6788e-02,  3.4882e-02,  8.3834e-03, -1.3198e-02,  1.1451e-01,
         -1.1505e-01, -3.5800e-02, -1.0463e-01, -1.1352e-01,  5.7093e-02,
          8.9621e-02,  1.1799e-02],
        [-3.4141e-01, -6.8257e-02,  1.7406e-01,  3.3480e-01, -1.6265e-01,
          2.4690e-03,  7.8161e-02, -2.6883e-01,  2.2998e-02, -2.0317e-02,
         -1.7068e-02,  1.8112e-01, -1.9071e-01, -4.4045e-01, -2.4359e-01,
         -1.7638e-01, -2.6806e-01, -1.4784e-01, -3.3921e-02,  6.5400e-02,
          5.1167e-03,  8.6204e-02, -6.9846e-02, -1.0460e-01,  1.7183e-01,
         -2.6373e-01, -5.7008e-02, -8.8608e-02, -1.0350e-01,  1.7246e-01,
          6.8501e-02, -4.5106e-02],
        [ 1.8838e-01,  1.4377e-01, -2.2571e-01, -3.9919e-01,  2.4835e-01,
          6.3393e-03, -1.2360e-01,  2.9627e-01,  2.0661e-02,  1.2291e-02,
         -3.4572e-02, -1.6648e-01,  6.6376e-02,  3.9827e-01,  2.0639e-01,
          4.0636e-02,  2.8847e-01,  1.0920e-01,  5.7693e-02, -7.0728e-02,
         -9.5562e-02, -1.0284e-01,  1.3093e-01,  1.6262e-01, -1.4654e-01,
          3.0379e-01,  5.1465e-02,  1.6353e-02,  3.0391e-02, -2.2223e-01,
         -1.2958e-03,  9.2848e-02],
        [ 9.4190e-02,  7.1886e-02, -1.1285e-01, -1.9960e-01,  1.2418e-01,
          3.1697e-03, -6.1798e-02,  1.4813e-01,  1.0330e-02,  6.1455e-03,
         -1.7286e-02, -8.3239e-02,  3.3188e-02,  1.9913e-01,  1.0319e-01,
          2.0318e-02,  1.4424e-01,  5.4599e-02,  2.8846e-02, -3.5364e-02,
         -4.7781e-02, -5.1418e-02,  6.5465e-02,  8.1310e-02, -7.3272e-02,
          1.5190e-01,  2.5732e-02,  8.1763e-03,  1.5195e-02, -1.1111e-01,
         -6.4792e-04,  4.6424e-02],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-9.4190e-02, -7.1886e-02,  1.1285e-01,  1.9960e-01, -1.2418e-01,
         -3.1697e-03,  6.1798e-02, -1.4813e-01, -1.0330e-02, -6.1455e-03,
          1.7286e-02,  8.3239e-02, -3.3188e-02, -1.9913e-01, -1.0319e-01,
         -2.0318e-02, -1.4424e-01, -5.4599e-02, -2.8846e-02,  3.5364e-02,
          4.7781e-02,  5.1418e-02, -6.5465e-02, -8.1310e-02,  7.3272e-02,
         -1.5190e-01, -2.5732e-02, -8.1763e-03, -1.5195e-02,  1.1111e-01,
          6.4792e-04, -4.6424e-02],
        [-1.8838e-01, -1.4377e-01,  2.2571e-01,  3.9919e-01, -2.4835e-01,
         -6.3393e-03,  1.2360e-01, -2.9627e-01, -2.0661e-02, -1.2291e-02,
          3.4572e-02,  1.6648e-01, -6.6376e-02, -3.9827e-01, -2.0639e-01,
         -4.0636e-02, -2.8847e-01, -1.0920e-01, -5.7693e-02,  7.0728e-02,
          9.5562e-02,  1.0284e-01, -1.3093e-01, -1.6262e-01,  1.4654e-01,
         -3.0379e-01, -5.1465e-02, -1.6353e-02, -3.0391e-02,  2.2223e-01,
          1.2958e-03, -9.2848e-02],
        [ 3.4141e-01,  6.8257e-02, -1.7406e-01, -3.3480e-01,  1.6265e-01,
         -2.4690e-03, -7.8161e-02,  2.6883e-01, -2.2998e-02,  2.0317e-02,
          1.7068e-02, -1.8112e-01,  1.9071e-01,  4.4045e-01,  2.4359e-01,
          1.7638e-01,  2.6806e-01,  1.4784e-01,  3.3921e-02, -6.5400e-02,
         -5.1167e-03, -8.6204e-02,  6.9846e-02,  1.0460e-01, -1.7183e-01,
          2.6373e-01,  5.7008e-02,  8.8608e-02,  1.0350e-01, -1.7246e-01,
         -6.8501e-02,  4.5106e-02],
        [ 3.0664e-01, -2.0371e-02, -5.6521e-02, -1.3563e-01,  2.4005e-02,
         -8.1458e-03, -8.2610e-03,  1.2759e-01, -4.6327e-02,  1.7416e-02,
          4.9190e-02, -1.1146e-01,  2.0120e-01,  2.7609e-01,  1.6338e-01,
          2.0204e-01,  1.3256e-01,  1.1152e-01,  4.6568e-04, -3.2074e-02,
          6.6788e-02, -3.4882e-02, -8.3834e-03,  1.3198e-02, -1.1451e-01,
          1.1505e-01,  3.5800e-02,  1.0463e-01,  1.1352e-01, -5.7093e-02,
         -8.9621e-02, -1.1799e-02],
        [ 2.3362e-01, -9.3664e-02,  5.2430e-02,  5.4601e-02, -9.8513e-02,
         -1.1878e-02,  5.2967e-02, -1.1734e-02, -5.9856e-02,  1.2473e-02,
          6.9873e-02, -3.5919e-02,  1.8190e-01,  9.6023e-02,  7.1465e-02,
          1.9568e-01, -2.5189e-03,  6.4617e-02, -2.8349e-02,  1.0748e-03,
          1.1918e-01,  1.4128e-02, -7.4427e-02, -6.7201e-02, -4.9141e-02,
         -2.8902e-02,  1.2539e-02,  1.0368e-01,  1.0617e-01,  5.0080e-02,
         -9.5160e-02, -5.9037e-02],
        [ 1.3043e-01, -1.5486e-01,  1.5461e-01,  2.3778e-01, -2.0831e-01,
         -1.4076e-02,  1.0735e-01, -1.4954e-01, -6.5654e-02,  5.9190e-03,
          8.1529e-02,  4.4264e-02,  1.3911e-01, -9.6452e-02, -2.9680e-02,
          1.6403e-01, -1.3728e-01,  9.3710e-03, -5.3501e-02,  3.4085e-02,
          1.5618e-01,  6.1312e-02, -1.3086e-01, -1.3892e-01,  2.2572e-02,
         -1.6912e-01, -1.2341e-02,  8.9334e-02,  8.5095e-02,  1.5078e-01,
         -8.8408e-02, -9.8650e-02],
        [-1.1017e-02, -2.0072e-01,  2.4820e-01,  4.1202e-01, -3.0197e-01,
         -1.4329e-02,  1.5307e-01, -2.8543e-01, -6.1651e-02, -2.6773e-03,
          8.1747e-02,  1.3033e-01,  6.6533e-02, -3.0465e-01, -1.4253e-01,
          1.0035e-01, -2.7162e-01, -5.6454e-02, -7.4012e-02,  6.6920e-02,
          1.7366e-01,  1.0618e-01, -1.7510e-01, -1.9964e-01,  1.0233e-01,
         -3.0461e-01, -3.9274e-02,  5.8015e-02,  4.6642e-02,  2.4329e-01,
         -6.6076e-02, -1.2860e-01],
        [ 4.6360e-01, -3.0798e-02, -8.5452e-02, -2.0506e-01,  3.6293e-02,
         -1.2315e-02, -1.2489e-02,  1.9290e-01, -7.0040e-02,  2.6331e-02,
          7.4368e-02, -1.6851e-01,  3.0418e-01,  4.1742e-01,  2.4701e-01,
          3.0546e-01,  2.0042e-01,  1.6860e-01,  7.0405e-04, -4.8492e-02,
          1.0097e-01, -5.2736e-02, -1.2674e-02,  1.9953e-02, -1.7312e-01,
          1.7394e-01,  5.4125e-02,  1.5819e-01,  1.7163e-01, -8.6316e-02,
         -1.3549e-01, -1.7838e-02],
        [ 5.0367e-01, -1.2440e-01,  1.8287e-02, -3.8988e-02, -9.6496e-02,
         -1.9980e-02,  5.5394e-02,  8.2794e-02, -1.0468e-01,  2.7681e-02,
          1.1850e-01, -1.2606e-01,  3.6377e-01,  3.2045e-01,  2.0667e-01,
          3.8044e-01,  9.7278e-02,  1.5949e-01, -3.2638e-02, -2.2995e-02,
          1.8918e-01, -9.9276e-03, -9.2950e-02, -6.8227e-02, -1.4375e-01,
          5.3336e-02,  4.1655e-02,  1.9975e-01,  2.0936e-01,  1.5121e-02,
         -1.7849e-01, -7.7622e-02],
        [ 4.6725e-01, -1.8733e-01,  1.0486e-01,  1.0920e-01, -1.9703e-01,
         -2.3756e-02,  1.0593e-01, -2.3468e-02, -1.1971e-01,  2.4946e-02,
          1.3975e-01, -7.1837e-02,  3.6380e-01,  1.9205e-01,  1.4293e-01,
          3.9135e-01, -5.0378e-03,  1.2923e-01, -5.6697e-02,  2.1496e-03,
          2.3836e-01,  2.8255e-02, -1.4885e-01, -1.3440e-01, -9.8283e-02,
         -5.7804e-02,  2.5079e-02,  2.0736e-01,  2.1233e-01,  1.0016e-01,
         -1.9032e-01, -1.1807e-01],
        [ 3.7047e-01, -2.2606e-01,  1.7789e-01,  2.4328e-01, -2.7211e-01,
         -2.4463e-02,  1.4279e-01, -1.2670e-01, -1.1929e-01,  1.8990e-02,
          1.4294e-01, -8.3387e-03,  3.1684e-01,  3.8834e-02,  6.0730e-02,
          3.5171e-01, -1.0670e-01,  8.2280e-02, -7.3433e-02,  2.7017e-02,
          2.5675e-01,  6.2788e-02, -1.8553e-01, -1.8322e-01, -4.0124e-02,
         -1.6148e-01,  5.2636e-03,  1.8818e-01,  1.8787e-01,  1.7226e-01,
         -1.7757e-01, -1.4328e-01],
        [ 1.9719e-01, -2.3412e-01,  2.3375e-01,  3.5949e-01, -3.1493e-01,
         -2.1280e-02,  1.6230e-01, -2.2609e-01, -9.9259e-02,  8.9487e-03,
          1.2326e-01,  6.6921e-02,  2.1031e-01, -1.4582e-01, -4.4872e-02,
          2.4799e-01, -2.0754e-01,  1.4168e-02, -8.0886e-02,  5.1532e-02,
          2.3612e-01,  9.2696e-02, -1.9784e-01, -2.1003e-01,  3.4126e-02,
         -2.5569e-01, -1.8658e-02,  1.3506e-01,  1.2865e-01,  2.2796e-01,
         -1.3366e-01, -1.4914e-01]], device='cuda:0')
Tx_1
tensor([[ 2.3570e-01,  2.3570e-01],
        [-1.1785e-01,  3.1180e-01],
        [ 0.0000e+00,  3.3333e-01],
        [ 1.1785e-01,  3.1180e-01],
        [-2.3570e-01,  2.3570e-01],
        [ 3.1180e-01, -1.1785e-01],
        [-1.5590e-01, -1.5590e-01],
        [ 0.0000e+00, -1.6667e-01],
        [ 1.5590e-01, -1.5590e-01],
        [-3.1180e-01, -1.1785e-01],
        [ 3.3333e-01,  0.0000e+00],
        [-1.6667e-01,  0.0000e+00],
        [ 0.0000e+00, -1.4901e-08],
        [ 1.6667e-01,  0.0000e+00],
        [-3.3333e-01,  0.0000e+00],
        [ 3.1180e-01,  1.1785e-01],
        [-1.5590e-01,  1.5590e-01],
        [ 0.0000e+00,  1.6667e-01],
        [ 1.5590e-01,  1.5590e-01],
        [-3.1180e-01,  1.1785e-01],
        [ 2.3570e-01, -2.3570e-01],
        [-1.1785e-01, -3.1180e-01],
        [ 0.0000e+00, -3.3333e-01],
        [ 1.1785e-01, -3.1180e-01],
        [-2.3570e-01, -2.3570e-01]], device='cuda:0')
x1
tensor([[ 1.5794e-01,  6.2170e-02, -4.6290e-01, -3.3400e-01,  6.0280e-01,
          3.1293e-01, -2.8718e-01,  3.7476e-02, -2.5424e-01,  5.1407e-01,
          1.1102e-01,  1.9979e-01, -2.1308e-01,  1.5863e-01,  2.2187e-01,
         -5.5614e-01,  5.6940e-01,  4.1891e-01,  2.0830e-01, -2.4687e-01,
         -8.2139e-01,  1.0417e-02,  4.3356e-01,  1.7401e-02,  1.5854e-02,
         -2.1818e-01, -2.0181e-01, -3.2436e-01, -1.2464e-01,  9.0084e-02,
         -7.4279e-01,  6.6686e-01],
        [-5.1290e-01, -1.4147e-01, -8.6343e-02, -5.5179e-01,  7.6780e-01,
          2.6994e-01,  5.2777e-01,  2.4777e-01, -1.1198e-01,  1.3807e-01,
         -8.9997e-03,  5.0822e-01, -2.9019e-01,  2.4580e-01, -1.1363e-01,
         -5.0269e-01,  9.6590e-01, -5.1954e-04,  1.1597e-01, -3.4919e-01,
         -4.3643e-01,  5.8383e-01,  3.1738e-01,  3.7478e-01, -1.5719e-01,
         -1.3577e-01, -3.3894e-01, -1.8905e-01, -2.1583e-01, -3.5656e-01,
          1.1769e-01,  1.0862e+00],
        [-4.9224e-01, -1.8812e-01,  6.9533e-02, -3.2612e-01,  5.2188e-01,
          2.4630e-01,  4.9697e-01,  9.8734e-02, -6.1363e-02,  4.6371e-01,
         -1.0710e-01,  5.3489e-01, -4.7735e-01,  1.0788e-01, -1.6344e-01,
         -5.6591e-01,  6.4263e-01,  9.2446e-04, -5.8900e-02, -1.9510e-01,
         -4.5977e-01,  6.3892e-01,  3.6394e-01,  1.7404e-01, -1.9477e-01,
         -2.1487e-01, -4.0988e-01, -2.9338e-01, -1.4672e-01, -2.0931e-01,
          6.4390e-02,  7.4282e-01],
        [-4.0800e-01, -2.1047e-01,  2.1643e-01, -5.8314e-02,  2.0855e-01,
          1.9085e-01,  4.0197e-01, -6.3058e-02, -2.8202e-03,  7.2945e-01,
         -1.9137e-01,  4.9246e-01, -6.0286e-01, -4.3982e-02, -1.9214e-01,
         -5.5602e-01,  2.3635e-01,  2.2491e-03, -2.2616e-01, -1.5805e-02,
         -4.2372e-01,  6.1148e-01,  3.6349e-01, -4.9185e-02, -2.0720e-01,
         -2.6622e-01, -4.2786e-01, -3.5981e-01, -5.8664e-02, -3.5019e-02,
          2.7768e-03,  3.0348e-01],
        [-8.5407e-01, -3.2821e-01,  5.6124e-01, -1.2720e-01,  1.3525e-01,
          3.5401e-02,  9.9000e-01,  1.0215e-01,  1.6746e-01,  1.4171e-01,
         -2.6249e-01,  5.5666e-01, -4.6200e-01, -6.0639e-03, -4.5301e-01,
         -2.4418e-01,  3.3942e-01, -4.1761e-01, -2.9159e-01, -2.9042e-02,
          1.7118e-01,  8.9316e-01,  8.1130e-02,  2.2873e-01, -2.9131e-01,
         -8.5695e-02, -3.7785e-01, -9.0543e-02, -8.2860e-02, -3.8609e-01,
          8.3385e-01,  3.8365e-01],
        [ 7.2701e-01,  2.7846e-01, -6.2999e-01,  1.2460e-01,  4.4223e-01,
          2.1354e-01, -9.3423e-01, -8.8276e-02, -1.2001e-02,  2.8200e-01,
          5.1265e-02, -1.2744e-01,  4.2029e-02,  1.7910e-01,  4.7072e-01,
         -1.2057e-01,  1.4124e-01,  5.2054e-01,  3.4133e-01, -3.6787e-01,
         -7.7517e-01, -6.8903e-01,  2.8264e-01, -1.9390e-01,  2.6047e-01,
         -3.6970e-02,  2.9009e-01, -8.8340e-02, -2.8358e-01,  1.8452e-01,
         -9.5913e-01,  2.2373e-01],
        [ 6.8531e-03,  7.2431e-02, -1.3755e-01,  1.9369e-02,  5.4581e-01,
          9.1957e-02, -3.5126e-02,  1.4541e-01,  2.8090e-01, -3.4391e-01,
         -1.3838e-01,  1.5410e-01,  4.4609e-02,  2.8450e-01,  8.4115e-02,
          1.4874e-01,  4.6816e-01, -4.5176e-02,  2.4043e-01, -5.1656e-01,
         -1.6535e-01, -1.5740e-01,  3.5022e-02,  2.0883e-01,  1.0889e-01,
          1.5330e-01,  2.8854e-01,  2.0067e-01, -4.4254e-01, -3.8524e-01,
          1.8676e-01,  5.6590e-01],
        [ 8.1499e-02,  2.8637e-02,  6.7046e-02,  3.6965e-01,  1.8804e-01,
          4.2383e-02, -1.2650e-01, -6.4340e-02,  3.7749e-01,  5.0506e-02,
         -2.7689e-01,  1.5359e-01, -1.7341e-01,  9.9230e-02,  3.4409e-02,
          1.2131e-01, -1.5388e-02, -4.6337e-02,  1.5103e-02, -3.1648e-01,
         -1.6779e-01, -1.4871e-01,  7.0040e-02, -7.6542e-02,  8.1044e-02,
          7.1646e-02,  2.4559e-01,  9.3785e-02, -3.6196e-01, -1.8447e-01,
          1.1840e-01,  5.1489e-02],
        [ 1.4562e-01, -1.8856e-02,  2.6298e-01,  6.7218e-01, -1.9401e-01,
         -1.2666e-02, -2.0154e-01, -2.6578e-01,  4.2531e-01,  4.3840e-01,
         -3.7963e-01,  1.3324e-01, -3.6902e-01, -9.8854e-02, -1.9741e-02,
          7.8198e-02, -4.9695e-01, -4.1513e-02, -2.1217e-01, -7.5525e-02,
         -1.4855e-01, -1.2082e-01,  9.6012e-02, -3.5202e-01,  4.2725e-02,
         -1.9263e-02,  1.7091e-01, -2.5217e-02, -2.3463e-01,  4.0122e-02,
          3.4749e-02, -4.6957e-01],
        [-6.1175e-01, -2.3797e-01,  7.2481e-01,  3.9816e-01, -1.7629e-01,
         -1.5360e-01,  7.5533e-01, -2.7142e-03,  5.4585e-01, -2.1058e-01,
         -4.4285e-01,  3.4465e-01, -2.8726e-01, -3.8766e-02, -4.2206e-01,
          2.9212e-01, -1.6300e-01, -5.8607e-01, -3.1997e-01, -7.9705e-02,
          5.3788e-01,  4.7872e-01, -1.8359e-01,  8.5655e-02, -1.4586e-01,
          1.3829e-01,  5.7217e-02,  2.2097e-01, -2.2831e-01, -4.4540e-01,
          1.1266e+00, -1.5092e-01],
        [ 7.1559e-01,  2.7604e-01, -7.2417e-01, -1.4623e-01,  3.3061e-01,
          1.9624e-01, -9.0311e-01, -4.5735e-02, -2.9818e-01,  2.6329e-01,
          2.6411e-01, -2.5234e-01,  1.7601e-01,  1.1645e-01,  4.7721e-01,
         -2.2059e-01,  1.6262e-01,  5.9151e-01,  3.5348e-01, -1.5403e-01,
         -7.0186e-01, -6.2419e-01,  2.4921e-01, -1.4943e-01,  2.1720e-01,
         -9.3682e-02,  1.2448e-01, -1.6533e-01, -2.9540e-02,  3.3671e-01,
         -1.1149e+00,  2.0026e-01],
        [-7.4173e-02,  4.8795e-02, -2.1409e-01, -3.4894e-01,  3.9545e-01,
          5.5923e-02,  8.8950e-02,  2.1979e-01, -7.7187e-02, -4.1817e-01,
          1.2896e-01,  1.1149e-02,  2.2109e-01,  2.0491e-01,  5.5513e-02,
          3.7708e-02,  5.1587e-01, -1.9577e-03,  2.4193e-01, -2.3574e-01,
         -8.9827e-03, -1.9552e-02, -3.2601e-02,  2.9979e-01,  3.5369e-02,
          9.2239e-02,  6.2876e-02,  1.2074e-01, -1.1113e-01, -2.2736e-01,
          8.1253e-02,  5.5348e-01],
        [ 4.3748e-08,  7.4073e-09,  1.1252e-07,  3.1835e-08, -5.7824e-08,
         -5.3888e-08, -1.0146e-08, -1.6176e-09, -2.2052e-09,  9.7857e-08,
         -3.5921e-08, -1.4436e-08, -4.4559e-08,  2.5709e-08, -8.2270e-08,
          9.7910e-10,  2.0282e-08,  2.3334e-08, -1.0462e-07, -4.8911e-08,
         -7.4411e-08,  7.1443e-08,  3.2522e-08, -3.3065e-09, -4.0176e-08,
         -2.3797e-08,  1.1054e-08,  1.0964e-07,  3.1460e-09, -3.6981e-08,
          1.7881e-08, -5.6962e-08],
        [ 7.4173e-02, -4.8795e-02,  2.1409e-01,  3.4894e-01, -3.9545e-01,
         -5.5923e-02, -8.8950e-02, -2.1979e-01,  7.7188e-02,  4.1817e-01,
         -1.2896e-01, -1.1149e-02, -2.2109e-01, -2.0491e-01, -5.5513e-02,
         -3.7708e-02, -5.1587e-01,  1.9577e-03, -2.4193e-01,  2.3574e-01,
          8.9826e-03,  1.9552e-02,  3.2601e-02, -2.9979e-01, -3.5369e-02,
         -9.2239e-02, -6.2875e-02, -1.2074e-01,  1.1113e-01,  2.2736e-01,
         -8.1254e-02, -5.5348e-01],
        [-7.1559e-01, -2.7604e-01,  7.2417e-01,  1.4623e-01, -3.3061e-01,
         -1.9624e-01,  9.0311e-01,  4.5735e-02,  2.9818e-01, -2.6329e-01,
         -2.6411e-01,  2.5234e-01, -1.7601e-01, -1.1645e-01, -4.7721e-01,
          2.2059e-01, -1.6262e-01, -5.9151e-01, -3.5348e-01,  1.5403e-01,
          7.0186e-01,  6.2419e-01, -2.4921e-01,  1.4943e-01, -2.1720e-01,
          9.3682e-02, -1.2448e-01,  1.6533e-01,  2.9540e-02, -3.3671e-01,
          1.1149e+00, -2.0026e-01],
        [ 6.1175e-01,  2.3797e-01, -7.2481e-01, -3.9816e-01,  1.7629e-01,
          1.5360e-01, -7.5533e-01,  2.7143e-03, -5.4585e-01,  2.1058e-01,
          4.4285e-01, -3.4465e-01,  2.8726e-01,  3.8766e-02,  4.2206e-01,
         -2.9212e-01,  1.6300e-01,  5.8607e-01,  3.1997e-01,  7.9705e-02,
         -5.3788e-01, -4.7872e-01,  1.8359e-01, -8.5655e-02,  1.4586e-01,
         -1.3829e-01, -5.7217e-02, -2.2097e-01,  2.2831e-01,  4.4540e-01,
         -1.1266e+00,  1.5092e-01],
        [-1.4562e-01,  1.8857e-02, -2.6298e-01, -6.7218e-01,  1.9401e-01,
          1.2666e-02,  2.0154e-01,  2.6578e-01, -4.2531e-01, -4.3840e-01,
          3.7963e-01, -1.3324e-01,  3.6902e-01,  9.8854e-02,  1.9741e-02,
         -7.8198e-02,  4.9695e-01,  4.1514e-02,  2.1217e-01,  7.5524e-02,
          1.4855e-01,  1.2082e-01, -9.6011e-02,  3.5202e-01, -4.2725e-02,
          1.9263e-02, -1.7091e-01,  2.5217e-02,  2.3463e-01, -4.0122e-02,
         -3.4749e-02,  4.6957e-01],
        [-8.1499e-02, -2.8637e-02, -6.7046e-02, -3.6965e-01, -1.8804e-01,
         -4.2383e-02,  1.2650e-01,  6.4340e-02, -3.7749e-01, -5.0506e-02,
          2.7689e-01, -1.5359e-01,  1.7341e-01, -9.9230e-02, -3.4409e-02,
         -1.2131e-01,  1.5388e-02,  4.6338e-02, -1.5103e-02,  3.1648e-01,
          1.6779e-01,  1.4871e-01, -7.0040e-02,  7.6542e-02, -8.1044e-02,
         -7.1646e-02, -2.4559e-01, -9.3786e-02,  3.6196e-01,  1.8447e-01,
         -1.1840e-01, -5.1489e-02],
        [-6.8527e-03, -7.2431e-02,  1.3755e-01, -1.9370e-02, -5.4581e-01,
         -9.1957e-02,  3.5126e-02, -1.4541e-01, -2.8091e-01,  3.4391e-01,
          1.3838e-01, -1.5410e-01, -4.4609e-02, -2.8450e-01, -8.4115e-02,
         -1.4874e-01, -4.6816e-01,  4.5176e-02, -2.4043e-01,  5.1656e-01,
          1.6535e-01,  1.5740e-01, -3.5021e-02, -2.0883e-01, -1.0889e-01,
         -1.5330e-01, -2.8854e-01, -2.0067e-01,  4.4254e-01,  3.8524e-01,
         -1.8676e-01, -5.6590e-01],
        [-7.2701e-01, -2.7846e-01,  6.2999e-01, -1.2460e-01, -4.4223e-01,
         -2.1354e-01,  9.3423e-01,  8.8276e-02,  1.2001e-02, -2.8200e-01,
         -5.1265e-02,  1.2744e-01, -4.2029e-02, -1.7910e-01, -4.7072e-01,
          1.2057e-01, -1.4124e-01, -5.2054e-01, -3.4133e-01,  3.6787e-01,
          7.7517e-01,  6.8903e-01, -2.8264e-01,  1.9390e-01, -2.6047e-01,
          3.6970e-02, -2.9009e-01,  8.8340e-02,  2.8358e-01, -1.8452e-01,
          9.5913e-01, -2.2373e-01],
        [ 8.5407e-01,  3.2821e-01, -5.6124e-01,  1.2720e-01, -1.3525e-01,
         -3.5401e-02, -9.9000e-01, -1.0216e-01, -1.6746e-01, -1.4171e-01,
          2.6249e-01, -5.5666e-01,  4.6200e-01,  6.0639e-03,  4.5301e-01,
          2.4418e-01, -3.3942e-01,  4.1761e-01,  2.9159e-01,  2.9042e-02,
         -1.7118e-01, -8.9316e-01, -8.1130e-02, -2.2873e-01,  2.9131e-01,
          8.5695e-02,  3.7785e-01,  9.0543e-02,  8.2860e-02,  3.8609e-01,
         -8.3385e-01, -3.8365e-01],
        [ 4.0800e-01,  2.1047e-01, -2.1643e-01,  5.8314e-02, -2.0855e-01,
         -1.9085e-01, -4.0197e-01,  6.3058e-02,  2.8203e-03, -7.2945e-01,
          1.9137e-01, -4.9246e-01,  6.0286e-01,  4.3982e-02,  1.9214e-01,
          5.5602e-01, -2.3635e-01, -2.2491e-03,  2.2616e-01,  1.5806e-02,
          4.2372e-01, -6.1148e-01, -3.6349e-01,  4.9185e-02,  2.0720e-01,
          2.6622e-01,  4.2786e-01,  3.5981e-01,  5.8664e-02,  3.5019e-02,
         -2.7768e-03, -3.0348e-01],
        [ 4.9224e-01,  1.8812e-01, -6.9533e-02,  3.2612e-01, -5.2188e-01,
         -2.4630e-01, -4.9697e-01, -9.8734e-02,  6.1363e-02, -4.6371e-01,
          1.0710e-01, -5.3489e-01,  4.7735e-01, -1.0788e-01,  1.6344e-01,
          5.6591e-01, -6.4263e-01, -9.2445e-04,  5.8900e-02,  1.9510e-01,
          4.5977e-01, -6.3892e-01, -3.6394e-01, -1.7404e-01,  1.9477e-01,
          2.1487e-01,  4.0988e-01,  2.9338e-01,  1.4672e-01,  2.0931e-01,
         -6.4390e-02, -7.4282e-01],
        [ 5.1290e-01,  1.4147e-01,  8.6343e-02,  5.5179e-01, -7.6780e-01,
         -2.6994e-01, -5.2777e-01, -2.4777e-01,  1.1198e-01, -1.3807e-01,
          8.9998e-03, -5.0822e-01,  2.9019e-01, -2.4580e-01,  1.1363e-01,
          5.0269e-01, -9.6590e-01,  5.1956e-04, -1.1597e-01,  3.4919e-01,
          4.3643e-01, -5.8383e-01, -3.1738e-01, -3.7478e-01,  1.5719e-01,
          1.3577e-01,  3.3894e-01,  1.8905e-01,  2.1583e-01,  3.5656e-01,
         -1.1769e-01, -1.0862e+00],
        [-1.5794e-01, -6.2170e-02,  4.6290e-01,  3.3400e-01, -6.0280e-01,
         -3.1293e-01,  2.8718e-01, -3.7476e-02,  2.5424e-01, -5.1407e-01,
         -1.1102e-01, -1.9979e-01,  2.1308e-01, -1.5863e-01, -2.2187e-01,
          5.5614e-01, -5.6940e-01, -4.1891e-01, -2.0830e-01,  2.4687e-01,
          8.2139e-01, -1.0417e-02, -4.3356e-01, -1.7401e-02, -1.5854e-02,
          2.1818e-01,  2.0181e-01,  3.2436e-01,  1.2464e-01, -9.0084e-02,
          7.4279e-01, -6.6686e-01]], device='cuda:0', grad_fn=<AddBackward0>)
output
tensor([[ 0.3085],
        [ 1.0920],
        [ 1.5325],
        [ 1.2373],
        [ 1.4297],
        [ 0.0184],
        [ 0.2014],
        [ 1.0517],
        [ 0.7255],
        [ 0.9252],
        [-0.3841],
        [ 0.4338],
        [ 1.3157],
        [ 0.7675],
        [ 1.1777],
        [-0.9501],
        [-0.1349],
        [ 0.4657],
        [-0.0346],
        [ 1.0649],
        [-1.2118],
        [-1.0322],
        [-0.6413],
        [-0.7055],
        [-0.1243]], device='cuda:0', grad_fn=<AddBackward0>)
output_paddle(TestNet(conv1+conv2))
Tensor(shape=[25, 1], dtype=float32, place=Place(gpu:0), stop_gradient=False,
       [[ 0.30845395],
        [ 1.09196639],
        [ 1.53252232],
        [ 1.23726261],
        [ 1.42966962],
        [ 0.01843908],
        [ 0.20142037],
        [ 1.05172884],
        [ 0.72553205],
        [ 0.92520165],
        [-0.38408417],
        [ 0.43375805],
        [ 1.31570363],
        [ 0.76748455],
        [ 1.17768991],
        [-0.95012259],
        [-0.13486400],
        [ 0.46565300],
        [-0.03463201],
        [ 1.06492662],
        [-1.21181548],
        [-1.03216803],
        [-0.64132786],
        [-0.70550513],
        [-0.12435006]])


loss
tensor(5.5476, device='cuda:0', grad_fn=<CopyBackwards>)
print
max Res= 2.911257266998291
er:3.1550796031951904
Reslist
[tensor([1.4174, 2.0779, 1.6636, 0.5851, 1.7914, 1.1431, 2.9113, 1.0980, 2.6725],
       device='cuda:0', grad_fn=<AbsBackward>)]

###paddle###
loss:5.54756689
print
max Res= 2.91125750541687
er:3.1550776958465576
Reslist
[Tensor(shape=[9], dtype=float32, place=Place(gpu:0), stop_gradient=False,
       [1.41740620, 2.07791114, 1.66359472, 0.58504969, 1.79136276, 1.14305687,
        2.91125751, 1.09796047, 2.67252970])]


BP
output_grad.model.parameters()
paddle
[[-4.20632458],
        [-1.67176259],
        [-3.68224621],
        [-3.33797359],
        [-4.19768667],
        [-1.62460041],
        [-5.05208874],
        [-1.34493077],
        [-2.49791098],
        [-3.71437263],
        [-2.24633312],
        [-3.07537103],
        [-3.07653022],
        [-1.53081357],
        [-2.36057925],
        [-3.03701472],
        [-4.35643578],
        [-2.28175020],
        [-2.39042354],
        [-2.50725460],
        [-4.25941467],
        [-4.41504955],
        [-2.21853161],
        [-2.12139177],
        [-1.58499360],
        [-1.39214170],
        [-2.73566127],
        [-1.97732437],
        [-2.24657845],
        [-2.68918991],
        [-4.65334511],
        [-4.97637844]])]
torch
tensor([[-4.2063, -1.6718, -3.6822, -3.3380, -4.1977, -1.6246, -5.0521, -1.3449,
         -2.4979, -3.7144, -2.2463, -3.0754, -3.0765, -1.5308, -2.3606, -3.0370,
         -4.3564, -2.2817, -2.3904, -2.5073, -4.2594, -4.4150, -2.2185, -2.1214,
         -1.5850, -1.3921, -2.7357, -1.9773, -2.2466, -2.6892, -4.6533, -4.9764]]

1. 测试模型
### TestNet ###
paddle loss 2
5.547561645507812500e+00
4.988384246826171875e+00
4.452902317047119141e+00
3.951506614685058594e+00
3.502841234207153320e+00

torch loss
5.547564506530761719e+00
4.988382339477539062e+00
4.452954292297363281e+00
3.951614379882812500e+00
3.502939939498901367e+00

2. 算例原模型
### PossionNet ###

paddle loss
8.466508388519287109e-01
4.463384151458740234e-01
3.496919155120849609e+00
3.027003407478332520e-01
6.217457652091979980e-01
7.225926518440246582e-01
7.182740569114685059e-01
6.945444345474243164e-01
6.584275960922241211e-01
6.128243207931518555e-01

torch loss 
8.466508388519287109e-01
4.463384449481964111e-01
3.496950626373291016e+00
3.026968538761138916e-01
6.217460036277770996e-01
7.225922942161560059e-01
7.182736396789550781e-01
6.945440173149108887e-01
6.584269404411315918e-01
6.128236055374145508e-01

3. 对齐所采用的方法：将torch中的初始化权重转换为paddle中的模型参数，并加载该初始化模型参数训练
4. 采用和torch相同的初始化和相同的随机种子并不能得到一致的初始化参数，导致损失函数对不齐
以其中一层为例：
[[ 0.01386931, -0.17469446],
         [-0.11488205, -0.12554556],
         [ 0.04391516, -0.00437480],
         [-0.04620507,  0.15054135],
         [-0.06673241, -0.21711476],
         [ 0.07734102,  0.10772257],
         [-0.14947987, -0.08855308],
         [-0.24339736,  0.00992903],
         [ 0.20167692, -0.03334558],
         [ 0.09030207, -0.09069623],
         [ 0.11097834, -0.20789710],
         [-0.27375698, -0.24783611],
         [ 0.11241088, -0.25713867],
         [ 0.07257137,  0.12323907],
         [-0.07566534,  0.17471631],
         [-0.20270929, -0.35941374],
         [ 0.39204994, -0.10860916],
         [ 0.16431800,  0.20210075],
         [-0.06240684,  0.36264217],
         [-0.16013926,  0.05487129],
         [-0.05192847,  0.04994003],
         [ 0.22988185,  0.01947018],
         [ 0.02243598, -0.38539538],
         [-0.02410686, -0.19303168],
         [-0.32041386, -0.06643917],
         [-0.14567925,  0.20519564],
         [-0.20902714, -0.25618500],
         [ 0.08234197,  0.10428618],
         [-0.35897443,  0.02037426],
         [ 0.15103088,  0.02583670],
         [ 0.09624844,  0.28342009],
         [-0.00599195, -0.12890913]]]

[[ 4.2225e-02, -1.9868e-01, -2.0380e-01,  6.5523e-02,  1.6437e-01,
          -2.3213e-01,  2.4426e-02, -1.1949e-01, -2.7955e-02, -1.4778e-01,
          -2.6085e-01,  2.7604e-01,  3.3344e-01,  6.7384e-02,  4.2664e-02,
          -1.7476e-01, -2.1702e-01,  2.3612e-01, -6.2095e-02, -1.5671e-01,
          -1.6129e-01,  2.0785e-01,  2.6905e-01,  7.9950e-02,  4.1499e-01,
           3.5506e-01, -8.1608e-03, -6.1803e-02, -6.7157e-02, -1.1845e-01,
           6.3908e-02, -3.0789e-02],
         [-6.3970e-03, -3.1084e-01, -5.2331e-02,  7.6674e-02,  2.3134e-02,
           1.0294e-01,  2.6043e-01,  1.8161e-01, -1.1779e-01, -2.6837e-02,
           4.5192e-02,  7.3504e-02,  9.7762e-03, -2.3829e-01,  4.5947e-01,
           8.7348e-02,  4.9213e-02, -1.2817e-01, -1.9876e-02,  1.1751e-01,
          -4.4349e-02,  2.0529e-01,  2.2135e-01,  8.9684e-02, -7.9053e-02,
          -1.2186e-01,  5.0109e-02,  4.7589e-02,  2.6426e-01, -3.0112e-01,
          -1.7712e-01,  1.7423e-01]]
5. 所有涉及到对模型输出进行切片的操作都会导致无法计算梯度
6. 误差对比
torch
Solution er =  0.00926917139440775
Mean Error Last 10 iterations= 0.012298253225162625
wallclock time of all epochs =  219.15798425674438

paddle
采用torch模型初始化参数
Solution er =  0.003743629902601242
Mean Error Last 10 iterations= 0.006452123518101871
wallclock time of all epochs =  313.3279950618744

不采用torch模型初始化参数
Solution er =  0.012329354882240295
Mean Error Last 10 iterations= 0.015211612172424793
wallclock time of all epochs =  315.4111189842224

demo1

torch loss
1.352412223815917969e+00
1.232279419898986816e+00
1.122811198234558105e+00
1.026244282722473145e+00
9.451663494110107422e-01
8.789636492729187012e-01
8.248366713523864746e-01
7.786719202995300293e-01
7.377970218658447266e-01
7.024564743041992188e-01

paddle loss
1.352411270141601562e+00
1.232286691665649414e+00
1.122811675071716309e+00
1.026243448257446289e+00
9.451667070388793945e-01
8.789642453193664551e-01
8.248366713523864746e-01
7.786732912063598633e-01
7.377998828887939453e-01
7.024579048156738281e-01

aistudio conda

nvcc -V 查看cuda
nvidia-smi 查看显存
source ~/miniconda3/bin/activate 启动miniconda


6.988595724105834961e-01
6.988595128059387207e-01

grad

epoch=0
paddle
[-0.00001028,  0.00006496,  0.00008638, -0.00002489, -0.00003294,
-0.00009147, -0.00000037,  0.00015530, -0.00036394,  0.00008046,
 0.00030131, -0.00021740,  0.00004408, -0.00004387, -0.00008450,
-0.00008653,  0.00003512,  0.00020848,  0.00003452,  0.        ,
-0.00004460, -0.00001092,  0.        , -0.00004215,  0.00001152,
 0.        ,  0.00005659,  0.        ,  0.00004671, -0.00002384,
 0.        , -0.00000570]
 torch
[-1.0279e-05,  6.4955e-05,  8.6377e-05, -2.4896e-05, -3.2938e-05,
-9.1473e-05, -3.6538e-07,  1.5530e-04, -3.6395e-04,  8.0462e-05,
 3.0131e-04, -2.1741e-04,  4.4077e-05, -4.3876e-05, -8.4502e-05,
-8.6533e-05,  3.5119e-05,  2.0848e-04,  3.4523e-05,  0.0000e+00,
-4.4601e-05, -1.0921e-05,  0.0000e+00, -4.2152e-05,  1.1517e-05,
 0.0000e+00,  5.6586e-05,  0.0000e+00,  4.6711e-05, -2.3840e-05,
 0.0000e+00, -5.6960e-06]
epoch=1
paddle
 [-0.00004922,  0.00008554, -0.00013984, -0.00096360, -0.00018135,
-0.00057958, -0.00000284, -0.00033594, -0.00104015, -0.00116090,
 0.00024158, -0.00010983, -0.00048282, -0.00152933, -0.00007846,
-0.00020390, -0.00044355, -0.00044144, -0.00016664,  0.        ,
-0.00115426,  0.00008296,  0.        , -0.00066507,  0.00003546,
 0.        ,  0.00000532,  0.        ,  0.00001173, -0.00002832,
 0.        , -0.00001921]
torch
[-4.8156e-05,  8.3702e-05, -1.3681e-04, -9.4237e-04, -1.7749e-04,
-5.6723e-04, -2.7784e-06, -3.2898e-04, -1.0174e-03, -1.1355e-03,
 2.3623e-04, -1.0723e-04, -4.7234e-04, -1.4959e-03, -7.6742e-05,
-1.9943e-04, -4.3384e-04, -4.3175e-04, -1.6322e-04,  0.0000e+00,
-1.1292e-03,  8.1139e-05,  0.0000e+00, -6.5065e-04,  3.4682e-05,
 0.0000e+00,  5.2382e-06,  0.0000e+00,  1.1507e-05, -2.7800e-05,
 0.0000e+00, -1.8777e-05]

[0.02597482, 0.04742646, 0.05539679, 0.43052876, 0.14562589, 0.29106691,
        0.00271007, 0.18347767, 0.46407700, 0.59875703, 0.02147459, 0.00476525,
        0.27422756, 0.65738529, 0.07351114, 0.08259535, 0.27239633, 0.18581581,
        0.07902924, 0.        , 0.52875757, -0.01840965, 0.        , 0.35452682,
        -0.00537415, 0.        , 0.03637677, 0.        , 0.00399930, 0.01582423,
        0.        , 0.02404419]

[ 0.00082733, -0.00068996,  0.00195346,  0.01182795,  0.00359001,
         0.00877754,  0.00007464,  0.00428343,  0.01610465,  0.01838782,
        -0.00106739,  0.00119700,  0.00757528,  0.02173427,  0.00161296,
         0.00278205,  0.00707104,  0.00534734,  0.00223619,  0.        ,
         0.01724220, -0.00111985,  0.        ,  0.01032596, -0.00041026,
         0.        ,  0.00046912,  0.        , -0.00009791,  0.00020090,
         0.        ,  0.00053074]

[-0.00016044,  0.00035004, -0.00046345, -0.00228765, -0.00048589,
        -0.00155291, -0.00001029, -0.00054239, -0.00326910, -0.00315146,
         0.00040768, -0.00061438, -0.00146839, -0.00442200, -0.00014475,
        -0.00055458, -0.00110842, -0.00102908, -0.00035254,  0.        ,
        -0.00370095,  0.00033842,  0.        , -0.00182510,  0.00012018,
         0.        ,  0.00010660,  0.        ,  0.00002946, -0.00000908,
         0.        , -0.00004456]

######## param

epoch 0
torch
[-2.28020564e-01  3.36443260e-02  8.71737599e-02  6.19829409e-02
  -2.61604358e-02  2.38862500e-01 -5.04843481e-02  8.91652629e-02
   1.95532918e-01 -7.85610825e-02 -9.33817774e-02 -1.18643090e-01
   2.76140392e-01 -9.96214971e-02 -6.25523180e-02 -2.53008902e-01
  -8.29717796e-03  1.57449454e-01 -6.47282898e-02  6.79572597e-02
  -2.90844262e-01 -5.15956104e-01  2.59367879e-02  9.40246060e-02
   9.20404270e-02  3.63774486e-02  1.80927455e-01  1.10058650e-01
   1.93620786e-01  1.52675033e-01 -5.33913262e-02 -1.10094734e-01]
paddle
[-2.28020564e-01  3.36443260e-02  8.71737599e-02  6.19829409e-02
  -2.61604358e-02  2.38862500e-01 -5.04843518e-02  8.91652629e-02
   1.95532918e-01 -7.85610825e-02 -9.33817774e-02 -1.18643090e-01
   2.76140392e-01 -9.96215045e-02 -6.25523180e-02 -2.53008902e-01
  -8.29717796e-03  1.57449454e-01 -6.47282898e-02  6.79572597e-02
  -2.90844262e-01 -5.15956104e-01  2.59367879e-02  9.40245613e-02
   9.20404270e-02  3.63774486e-02  1.80927455e-01  1.10058650e-01
   1.93620786e-01  1.52675033e-01 -5.33913262e-02 -1.10094734e-01]
epoch 1  1e-5
torch
[ 0.00186634 -0.00199838 -0.00072818  0.00176115  0.00185349  0.00184115
  0.00179433 -0.00061288  0.00192624 -0.00030494 -0.00198641  0.00193009
 -0.00032109  0.00176322  0.0019961   0.00194912 -0.00031206 -0.00062102
 -0.0004103   0.          0.00176975  0.00035103  0.          0.00178562
 -0.0019161   0.         -0.00173547  0.         -0.00182821  0.00200025
  0.          0.00190414]
paddle
[ 0.00186414, -0.00199755, -0.00071874,  0.00176077,  0.00185149,
         0.00183933,  0.00179284, -0.00060550,  0.00192358, -0.00030384,
        -0.00198822,  0.00193357, -0.00031963,  0.00176280,  0.00199714,
         0.00194654, -0.00031079, -0.00061307, -0.00040696,  0.        ,
         0.00176921,  0.00034883,  0.        ,  0.00178475, -0.00191345,
         0.        , -0.00173646,  0.        , -0.00183074,  0.00199999,
         0.        ,  0.00190149]

epoch 2  1e-5
torch
[ 0.00122883 -0.00263896 -0.00136633  0.00112366  0.00121551  0.00120365
  0.0011562  -0.00125106  0.00128914 -0.00094271 -0.0026391   0.00133173
 -0.00095897  0.00112578  0.00135852  0.00131228 -0.00094999 -0.00125903
 -0.00104812  0.          0.00113225  0.00098755  0.          0.00114796
 -0.00128225  0.         -0.0023752   0.         -0.00247492  0.00136328
  0.          0.0012659 ]
paddle
[ 0.00122662, -0.00263810, -0.00135691,  0.00112328,  0.00121351,
         0.00120183,  0.00115471, -0.00124370,  0.00128647, -0.00094160,
        -0.00264065,  0.00133240, -0.00095750,  0.00112536,  0.00135954,
         0.00130969, -0.00094872, -0.00125109, -0.00104478,  0.        ,
         0.00113170,  0.00098535,  0.        ,  0.00114708, -0.00127956,
         0.        , -0.00237615,  0.        , -0.00247723,  0.00136299,
         0.        ,  0.00126326]
epoch 3  1e-5
torch
[ 0.00068882 -0.0031555  -0.00190874  0.00058607  0.00067904  0.00066451
  0.00061804 -0.00178696  0.00074785 -0.00148235 -0.00314437  0.00071172
 -0.001497    0.00058512  0.00082389  0.00077178 -0.00148712 -0.00179781
 -0.00158647  0.          0.00059179  0.00154244  0.          0.00060929
 -0.00072134  0.         -0.00290649  0.         -0.0029905   0.00083439
  0.          0.00073068]
  paddle
[ 0.00068617, -0.00315430, -0.00189982,  0.00058531,  0.00067675,
         0.00066233,  0.00061618, -0.00177990,  0.00074473, -0.00148162,
        -0.00314557,  0.00071330, -0.00149587,  0.00058429,  0.00082462,
         0.00076875, -0.00148620, -0.00179023, -0.00158348,  0.        ,
         0.00059082,  0.00154109,  0.        ,  0.00060804, -0.00071757,
         0.        , -0.00290761,  0.        , -0.00299241,  0.00083386,
         0.        ,  0.00072776]
epoch 4 1e-5
torch
[ 0.00023566 -0.00359601 -0.00236283  0.0001345   0.00022737  0.00021164
  0.00016521 -0.0022384   0.00029408 -0.00193569 -0.00358153  0.00025893
 -0.00194893  0.00013171  0.00037304  0.00031848 -0.00193896 -0.00225031
 -0.00203915  0.          0.00013869  0.00200175  0.          0.00015673
 -0.00025919  0.         -0.0033571   0.         -0.00343019  0.00038762
  0.          0.00027931]
  paddle
[ 0.00023273, -0.00359461, -0.00235412,  0.00013352,  0.00022488,
         0.00020926,  0.00016308, -0.00223149,  0.00029070, -0.00193518,
        -0.00358261,  0.00026173, -0.00194799,  0.00013064,  0.00037358,
         0.00031520, -0.00193826, -0.00224290, -0.00203637,  0.        ,
         0.00013748,  0.00200072,  0.        ,  0.00015524, -0.00025485,
         0.        , -0.00335841,  0.        , -0.00343186,  0.00038694,
         0.        ,  0.00027615]
epoch 5 1e-5
torch
[-1.5446532e-04 -3.9770766e-03 -2.7533013e-03 -2.5411439e-04
 -1.6180659e-04 -1.7818465e-04 -2.2534558e-04 -2.6273017e-03
 -9.6078002e-05 -2.3258436e-03 -3.9634807e-03 -1.1208099e-04
 -2.3378858e-03 -2.5825447e-04 -1.5422436e-05 -7.1303759e-05
 -2.3279875e-03 -2.6394327e-03 -2.4289899e-03  0.0000000e+00
 -2.5094629e-04  2.3950108e-03  0.0000000e+00 -2.3277900e-04
  1.3583223e-04  0.0000000e+00 -3.7464253e-03  0.0000000e+00
 -3.8100316e-03  2.1423198e-06  0.0000000e+00 -1.0994466e-04]
paddle
[-0.00015761, -0.00397557, -0.00274473, -0.00025526, -0.00016445,
        -0.00018071, -0.00022770, -0.00262052, -0.00009964, -0.00232550,
        -0.00396484, -0.00010764, -0.00233709, -0.00025949, -0.00001505,
        -0.00007475, -0.00232746, -0.00263213, -0.00242637,  0.        ,
        -0.00025231,  0.00239410,  0.        , -0.00023444,  0.00014047,
         0.        , -0.00374794,  0.        , -0.00381171,  0.00000128,
         0.        , -0.00011331]
epoch 6 1e-5
torch 
[-0.00049513 -0.00431026 -0.00309431 -0.00059348 -0.00050161 -0.00051851
 -0.00056644 -0.00296708 -0.00043677 -0.00266657 -0.00429588 -0.00043801
 -0.00267764 -0.00059878 -0.00035463 -0.00041171 -0.00266774 -0.00297915
 -0.00276946  0.         -0.00059116  0.00273826  0.         -0.00057295
  0.00048078  0.         -0.00408651  0.         -0.0041406  -0.0003343
  0.         -0.00044987]
paddle
[-0.00049846, -0.00430869, -0.00308587, -0.00059477, -0.00050438,
        -0.00052117, -0.00056899, -0.00296044, -0.00044050, -0.00266637,
        -0.00429747, -0.00043214, -0.00267698, -0.00060015, -0.00035441,
        -0.00041530, -0.00266737, -0.00297194, -0.00276698,  0.        ,
        -0.00059266,  0.00273744,  0.        , -0.00057476,  0.00048569,
         0.        , -0.00408823,  0.        , -0.00414225, -0.00033532,
         0.        , -0.00045341]
epoch 7 1e-5
torch
[-0.00079542 -0.00460412 -0.00339483 -0.00089261 -0.00080123 -0.00081848
 -0.00086715 -0.00326668 -0.00073707 -0.00296691 -0.00458986 -0.00071931
 -0.00297718 -0.00089891 -0.00065365 -0.00071173 -0.00296729 -0.00327861
 -0.00306951  0.         -0.00089101  0.00304067  0.         -0.00087285
  0.00078463  0.         -0.00438644  0.         -0.0044317  -0.00063069
  0.         -0.00074961]
paddle
[-0.00079891, -0.00460255, -0.00338653, -0.00089402, -0.00080412,
        -0.00082126, -0.00086987, -0.00326016, -0.00074093, -0.00296685,
        -0.00459164, -0.00071069, -0.00297664, -0.00090040, -0.00065356,
        -0.00071544, -0.00296707, -0.00327150, -0.00306718,  0.        ,
        -0.00089261,  0.00303992,  0.        , -0.00087479,  0.00078981,
         0.        , -0.00438840,  0.        , -0.00443320, -0.00063174,
         0.        , -0.00075330]
epoch 8  1e-5
torch
[-0.00106192 -0.0048648  -0.0036615  -0.00115808 -0.00106737 -0.00108467
 -0.00113422 -0.00353271 -0.00100352 -0.00323349 -0.00485242 -0.00094636
 -0.00324308 -0.00116524 -0.00091906 -0.00097789 -0.00323332 -0.0035446
 -0.00333588  0.         -0.00115698  0.00330868  0.         -0.0011391
  0.00105398  0.         -0.00465306  0.         -0.00469051 -0.00089352
  0.         -0.00101583]
paddle
[-0.00106557, -0.00486322, -0.00365318, -0.00115960, -0.00107041,
        -0.00108756, -0.00113707, -0.00352625, -0.00100751, -0.00323354,
        -0.00485447, -0.00093438, -0.00324265, -0.00116683, -0.00091907,
        -0.00098171, -0.00323323, -0.00353753, -0.00333364,  0.        ,
        -0.00115867,  0.00330797,  0.        , -0.00114116,  0.00105940,
         0.        , -0.00465529,  0.        , -0.00469203, -0.00089461,
         0.        , -0.00101967]
epoch 9 1e-5
torch
[-0.00129976 -0.00509723 -0.00389914 -0.00139493 -0.00130512 -0.0013222
 -0.00137259 -0.00376995 -0.00124126 -0.00347134 -0.00508854 -0.00112226
 -0.00348035 -0.00140278 -0.0011559  -0.00121528 -0.00347084 -0.00378194
 -0.00357353  0.         -0.00139417  0.00354733  0.         -0.00137675
  0.00129405  0.         -0.00489137  0.         -0.00492262 -0.00112766
  0.         -0.00125371]
paddle
[-0.00130352, -0.00509562, -0.00389094, -0.00139652, -0.00130832,
        -0.00132517, -0.00137548, -0.00376365, -0.00124532, -0.00347151,
        -0.00509072, -0.00110830, -0.00348004, -0.00140445, -0.00115601,
        -0.00121915, -0.00347091, -0.00377503, -0.00357142,  0.        ,
        -0.00139591,  0.00354671,  0.        , -0.00137891,  0.00129961,
         0.        , -0.00489387,  0.        , -0.00492450, -0.00112888,
         0.        , -0.00125763]
epoch 20 1e-5
torch
[-0.00270503 -0.00648109 -0.00528735 -0.00278492 -0.00271606 -0.00273263
 -0.00277828 -0.00518103 -0.00265547 -0.00488218 -0.00653596 -0.00210074
 -0.00488626 -0.00281084 -0.00257419 -0.00261706 -0.00488607 -0.00518717
 -0.00496527  0.         -0.00279887  0.00494312  0.         -0.00278552
  0.00262725  0.         -0.00632172  0.         -0.00626603 -0.00244823
  0.         -0.0026447 ]
paddle
[-0.00270868, -0.00647587, -0.00527741, -0.00278946, -0.00271910,
        -0.00273573, -0.00277836, -0.00517227, -0.00266114, -0.00488370,
        -0.00654838, -0.00203743, -0.00488712, -0.00281571, -0.00257517,
        -0.00262259, -0.00488600, -0.00518138, -0.00496508,  0.        ,
        -0.00280323,  0.00494802,  0.        , -0.00278932,  0.00264580,
         0.        , -0.00631881,  0.        , -0.00624100, -0.00243821,
         0.        , -0.00264600]
epoch 30 1e-4
torch
[-0.00327966 -0.00689045 -0.00584636 -0.00334136 -0.00329849 -0.00328408
 -0.00342441 -0.00572353 -0.00323044 -0.00544465 -0.00736362 -0.00379209
 -0.00540627 -0.00336812 -0.00317956 -0.00321356 -0.00545805 -0.00568141
 -0.00551958  0.         -0.00336365  0.00557959  0.         -0.00337641
  0.00299519  0.         -0.0066366   0.         -0.00564066 -0.00192895
  0.         -0.00316329]
paddle
[-0.00328661, -0.00692092, -0.00585131, -0.00335737, -0.00328467,
        -0.00327755, -0.00344611, -0.00572864, -0.00323284, -0.00545034,
        -0.00745829, -0.00338916, -0.00541832, -0.00339016, -0.00317078,
        -0.00319626, -0.00544785, -0.00569231, -0.00553894,  0.        ,
        -0.00337444,  0.00561022,  0.        , -0.00337624,  0.00316240,
         0.        , -0.00669791,  0.        , -0.00566922, -0.00202759,
         0.        , -0.00314531]
epoch50 1e-2
torch
[-0.00477965  0.00363753 -0.00547099 -0.00292897 -0.00622682  0.00175526
 -0.00340783 -0.00669011 -0.00385891 -0.00617643 -0.01317358 -0.01676918
  0.00224    -0.00378898 -0.00204546  0.0064956  -0.00161002  0.00061061
  0.00191792  0.         -0.00333873  0.00845118  0.         -0.00507443
 -0.01105382  0.          0.00698867  0.          0.00561893  0.01869252
  0.          0.00047268]
paddle
[-0.00417637, -0.01366445, -0.00352584, -0.00290965, -0.00752774,
         0.00230667, -0.00114503, -0.00800504, -0.00435804, -0.00658351,
        -0.01675645, -0.01872270,  0.00497747, -0.00372129, -0.00304413,
         0.00368463, -0.00122637,  0.00127319,  0.00522356,  0.        ,
        -0.00343032,  0.00342960,  0.        , -0.00626659, -0.00349685,
         0.        ,  0.00760664,  0.        ,  0.00454187,  0.02012476,
         0.        , -0.00047529]
epoch 100
torch
[-5.8333660e-03  1.3986877e-02 -8.8086398e-03 -3.7969369e-03
 -7.3409271e-03  4.7341026e-03  3.5938986e-03 -1.2763681e-02
 -3.7487138e-03 -6.1937473e-03 -2.0163560e-02 -2.6923008e-02
 -4.3482595e-07 -4.0911823e-03  7.2603492e-04  1.3640416e-02
  1.9216201e-03  7.4692066e-03  1.1731896e-03  0.0000000e+00
 -3.4012948e-03  3.3437442e-03  0.0000000e+00 -7.9105822e-03
 -2.0560173e-02  0.0000000e+00  9.7781522e-03  0.0000000e+00
  7.5394334e-03  3.2572757e-02  0.0000000e+00  7.3775179e-03]
paddle
[-0.00578244, -0.01567396, -0.00568520, -0.00293158, -0.00835918,
         0.00546727,  0.01860725, -0.01318771, -0.00452359, -0.00674993,
        -0.02438541, -0.02795197,  0.00744209, -0.00352444, -0.00414961,
        -0.00070830, -0.00107848,  0.00549777,  0.01854556,  0.        ,
        -0.00329531, -0.00728857,  0.        , -0.00736967, -0.01222265,
         0.        ,  0.01720743,  0.        ,  0.00136474,  0.03151650,
         0.        ,  0.00684918]

x_j
norm
adj_t
edge_index
edge_index_i
edge_index_j
ptr
index
size
size_i
size_j
dim_size

input 21.868896484375
0 22.313232421875
1 22.315185546875
2 22.317138671875
3 22.319091796875
4 22.321044921875
5 22.322998046875
6 22.324951171875
7 22.326904296875
after conv1 21.9140625
0 70.267578125
1 94.21044921875
2 118.1533203125
3 142.09619140625
4 166.0390625
5 189.98193359375
6 213.9248046875
7 237.86767578125
after conv2 237.537353515625
0 333.5009765625
1 381.221435546875
2 428.94189453125
3 476.662353515625
4 524.3828125
5 572.103271484375
6 619.82373046875
7 667.544189453125
after conv3 667.2138671875
0 858.398193359375
1 953.674072265625
2 1048.949951171875
3 1144.225830078125
4 1239.501708984375
5 1334.777587890625
6 1430.053466796875
7 1525.329345703125
after conv4 1524.9990234375
0 1906.295166015625
1 2096.681884765625
2 2287.068603515625
3 2477.455322265625
4 2667.842041015625
5 2858.228759765625
6 3048.615478515625
7 3239.002197265625
after conv5 3238.671875
0 3429.69140625
1 3524.96728515625
2 3620.2431640625
3 3715.51904296875
4 3810.794921875
5 3906.07080078125
6 4001.3466796875
7 4096.62255859375
0 4192.173583984375
1 4239.89404296875
2 4287.614501953125
3 4335.3349609375
4 4383.055419921875
5 4430.77587890625
6 4478.496337890625
7 4526.216796875
0 4574.18603515625
1 4598.12890625
2 4622.07177734375
3 4646.0146484375
4 4669.95751953125
5 4693.900390625
6 4717.84326171875
7 4741.7861328125
0 4741.900146484375
1 4741.902099609375
2 4741.904052734375
3 4741.906005859375
4 4741.907958984375
5 4741.909912109375
6 4741.911865234375
7 4741.913818359375
0 4789.8544921875
1 4813.79736328125
2 4837.740234375
3 4861.68310546875
4 4885.6259765625
5 4909.56884765625
6 4933.51171875
7 4957.45458984375
0 5053.087890625
1 5100.808349609375
2 5148.52880859375
3 5196.249267578125
4 5243.9697265625
5 5291.690185546875
6 5339.41064453125
7 5387.131103515625
0 5577.985107421875
1 5673.260986328125
2 5768.536865234375
3 5863.812744140625
4 5959.088623046875
5 6054.364501953125
6 6149.640380859375
7 6244.916259765625
0 6625.882080078125
1 6816.268798828125
2 7006.655517578125
3 7197.042236328125
4 7387.428955078125
5 7577.815673828125
6 7768.202392578125
7 7958.589111328125
after conv55 7958.2587890625
0 8149.2783203125
1 8244.55419921875
2 8339.830078125
3 8435.10595703125
4 8530.3818359375
5 8625.65771484375
6 8720.93359375
7 8816.20947265625
0 8911.760498046875
1 8959.48095703125
2 9007.201416015625
3 9054.921875
4 9102.642333984375
5 9150.36279296875
6 9198.083251953125
7 9245.8037109375
0 9293.77294921875
1 9317.7158203125
2 9341.65869140625
3 9365.6015625
4 9389.54443359375
5 9413.4873046875
6 9437.43017578125
7 9461.373046875
0 9461.233642578125
1 9461.234130859375
2 9461.234619140625
3 9461.235107421875
4 9461.235595703125
5 9461.236083984375
6 9461.236572265625
7 9461.237060546875
0 9482.366943359375
1 9492.924072265625
2 9503.481201171875
3 9514.038330078125
4 9524.595458984375
5 9535.152587890625
6 9545.709716796875
7 9556.266845703125
0 9598.41748046875
1 9619.458984375
2 9640.50048828125
3 9661.5419921875
4 9682.58349609375
5 9703.625
6 9724.66650390625
7 9745.7080078125
0 9829.827392578125
1 9871.837646484375
2 9913.847900390625
3 9955.858154296875
4 9997.868408203125
5 10039.878662109375
6 10081.888916015625
7 10123.899169921875
0 10291.8623046875
1 10375.81005859375
2 10459.7578125
3 10543.70556640625
4 10627.6533203125
5 10711.60107421875
6 10795.548828125
7 10879.49658203125
after conv555 10879.350830078125
0 10963.569091796875
1 11005.579345703125
2 11047.589599609375
3 11089.599853515625
4 11131.610107421875
5 11173.620361328125
6 11215.630615234375
7 11257.640869140625
0 11299.76806640625
1 11320.8095703125
2 11341.85107421875
3 11362.892578125
4 11383.93408203125
5 11404.9755859375
6 11426.01708984375
7 11447.05859375
0 11468.20947265625
1 11478.7666015625
2 11489.32373046875
3 11499.880859375
4 11510.43798828125
5 11520.9951171875
6 11531.55224609375
7 11542.109375
after conv888 11541.963623046875
loss 11546.43896484375
after step 50.689208984375

torch
input 11.9580078125
conv1 12.03125
conv2 12.8046875
conv3 13.93359375
conv4 15.7744140625
conv5 18.38427734375
conv6 19.89599609375
conv7 20.86083984375
conv55 27.951171875
conv555 33.17626953125
conv888 34.26220703125

torch epoch 10
41.62255859375

paddle propagate
before propagate 22.309326171875
after message 22.969482421875
after aggregate 22.806396484375
after update 22.806396484375
0 22.311279296875
after message 22.971435546875
after aggregate 22.808349609375
after update 22.808349609375
1 22.313232421875
after message 22.973388671875
after aggregate 22.810302734375
after update 22.810302734375
2 22.315185546875
after message 22.975341796875
after aggregate 22.812255859375
after update 22.812255859375
3 22.317138671875
after message 22.977294921875
after aggregate 22.814208984375
after update 22.814208984375
4 22.319091796875
after message 22.979248046875
after aggregate 22.816162109375
after update 22.816162109375
5 22.321044921875
after message 22.981201171875
after aggregate 22.818115234375
after update 22.818115234375
6 22.322998046875
after message 22.983154296875
after aggregate 22.820068359375
after update 22.820068359375
7 22.324951171875
after message 22.985107421875
after aggregate 22.822021484375
after update 22.822021484375
8 22.326904296875
before propagate 22.3818359375
after message 28.15478515625
after aggregate 46.65478515625
after update 46.65478515625
0 46.32470703125
after message 52.09765625
after aggregate 70.59765625
after update 70.59765625
1 70.267578125
after message 76.04052734375
after aggregate 94.54052734375
after update 94.54052734375
2 94.21044921875
after message 99.9833984375
after aggregate 118.4833984375
after update 118.4833984375
3 118.1533203125
after message 123.92626953125
after aggregate 142.42626953125
after update 142.42626953125
4 142.09619140625
after message 147.869140625
after aggregate 166.369140625
after update 166.369140625
5 166.0390625
after message 171.81201171875
after aggregate 190.31201171875
after update 190.31201171875
6 189.98193359375
after message 195.7548828125
after aggregate 214.2548828125
after update 214.2548828125
7 213.9248046875
after message 219.69775390625
after aggregate 238.19775390625
after update 238.19775390625
8 237.86767578125